{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0yGLaD04IkXxDgxMEfwgH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install g2p_en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRtVJo-5FMef","executionInfo":{"status":"ok","timestamp":1761978173603,"user_tz":-480,"elapsed":8411,"user":{"displayName":"E84116277楊宏文","userId":"06176082671217183653"}},"outputId":"a5e3dc8f-781a-4c41-c120-bf191e51c340"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting g2p_en\n","  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (2.0.2)\n","Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (3.9.1)\n","Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (7.5.0)\n","Collecting distance>=0.1.3 (from g2p_en)\n","  Downloading Distance-0.1.3.tar.gz (180 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (10.8.0)\n","Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (4.4.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (4.67.1)\n","Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en) (4.15.0)\n","Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: distance\n","  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=cf3bfbdbcadbdd9122df6e94c4c7c66f8a5d94cbd258b3939600cc0939fc6466\n","  Stored in directory: /root/.cache/pip/wheels/24/a8/58/407063d8e5c1d4dd6594c99d12baa0108570b56a92325587dd\n","Successfully built distance\n","Installing collected packages: distance, g2p_en\n","Successfully installed distance-0.1.3 g2p_en-2.1.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mv_4ugAKFG43","executionInfo":{"status":"ok","timestamp":1761978189674,"user_tz":-480,"elapsed":12601,"user":{"displayName":"E84116277楊宏文","userId":"06176082671217183653"}},"outputId":"344002dc-5ac7-47aa-e207-632f9d91daf3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package cmudict to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/cmudict.zip.\n"]}],"source":["import numpy as np\n","import re\n","from g2p_en import G2p\n","\n","\n","\n","LOGIT_PHONE_DEF = [\n","    'BLANK', 'SIL', # blank and silence\n","    'AA', 'AE', 'AH', 'AO', 'AW',\n","    'AY', 'B',  'CH', 'D', 'DH',\n","    'EH', 'ER', 'EY', 'F', 'G',\n","    'HH', 'IH', 'IY', 'JH', 'K',\n","    'L', 'M', 'N', 'NG', 'OW',\n","    'OY', 'P', 'R', 'S', 'SH',\n","    'T', 'TH', 'UH', 'UW', 'V',\n","    'W', 'Y', 'Z', 'ZH'\n","]\n","SIL_DEF = ['SIL']\n","\n","\n","# remove puntuation from text\n","def remove_punctuation(sentence):\n","    # Remove punctuation\n","    sentence = re.sub(r'[^a-zA-Z\\- \\']', '', sentence)\n","    sentence = sentence.replace('--', '').lower()\n","    sentence = sentence.replace(\" '\", \"'\").lower()\n","\n","    sentence = sentence.strip()\n","    sentence = ' '.join(sentence.split())\n","\n","    return sentence\n","\n","\n","# Convert RNN logits to argmax phonemes\n","def logits_to_phonemes(logits):\n","    seq = np.argmax(logits, axis=1)\n","    seq2 = np.array([seq[0]] + [seq[i] for i in range(1, len(seq)) if seq[i] != seq[i-1]])\n","\n","    phones = []\n","    for i in range(len(seq2)):\n","        phones.append(LOGIT_PHONE_DEF[seq2[i]])\n","\n","    # Remove blank and repeated phonemes\n","    phones = [p for p in phones if  p!='BLANK']\n","    phones = [phones[0]] + [phones[i] for i in range(1, len(phones)) if phones[i] != phones[i-1]]\n","\n","    return phones\n","\n","\n","# Convert text to phonemes\n","def sentence_to_phonemes(thisTranscription, g2p_instance=None):\n","    if not g2p_instance:\n","        g2p_instance = G2p()\n","\n","    # Remove punctuation\n","    thisTranscription = remove_punctuation(thisTranscription)\n","\n","    # Convert to phonemes\n","    phonemes = []\n","    if len(thisTranscription) == 0:\n","        phonemes = SIL_DEF\n","    else:\n","        for p in g2p_instance(thisTranscription):\n","            if p==' ':\n","                phonemes.append('SIL')\n","\n","            p = re.sub(r'[0-9]', '', p)  # Remove stress\n","            if re.match(r'[A-Z]+', p):  # Only keep phonemes\n","                phonemes.append(p)\n","\n","        #add one SIL symbol at the end so there's one at the end of each word\n","        phonemes.append('SIL')\n","\n","    return phonemes, thisTranscription\n","\n","\n","# Calculate WER or PER\n","def calculate_error_rate(r, h):\n","    \"\"\"\n","    Calculation of WER or PER with Levenshtein distance.\n","    Works only for iterables up to 254 elements (uint8).\n","    O(nm) time ans space complexity.\n","    ----------\n","    Parameters:\n","    r : list of true words or phonemes\n","    h : list of predicted words or phonemes\n","    ----------\n","    Returns:\n","    Word error rate (WER) or phoneme error rate (PER) [int]\n","    ----------\n","    Examples:\n","    >>> calculate_wer(\"who is there\".split(), \"is there\".split())\n","    1\n","    >>> calculate_wer(\"who is there\".split(), \"\".split())\n","    3\n","    >>> calculate_wer(\"\".split(), \"who is there\".split())\n","    3\n","    \"\"\"\n","    # initialization\n","    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n","    d = d.reshape((len(r)+1, len(h)+1))\n","    for i in range(len(r)+1):\n","        for j in range(len(h)+1):\n","            if i == 0:\n","                d[0][j] = j\n","            elif j == 0:\n","                d[i][0] = i\n","\n","    # computation\n","    for i in range(1, len(r)+1):\n","        for j in range(1, len(h)+1):\n","            if r[i-1] == h[j-1]:\n","                d[i][j] = d[i-1][j-1]\n","            else:\n","                substitution = d[i-1][j-1] + 1\n","                insertion    = d[i][j-1] + 1\n","                deletion     = d[i-1][j] + 1\n","                d[i][j] = min(substitution, insertion, deletion)\n","\n","    return d[len(r)][len(h)]\n","\n","\n","# calculate aggregate WER or PER\n","def calculate_aggregate_error_rate(r, h):\n","\n","    # list setup\n","    err_count = []\n","    item_count = []\n","    error_rate_ind = []\n","\n","    # calculate individual error rates\n","    for x in range(len(h)):\n","        r_x = r[x]\n","        h_x = h[x]\n","\n","        n_err = calculate_error_rate(r_x, h_x)\n","\n","        item_count.append(len(r_x))\n","        err_count.append(n_err)\n","        error_rate_ind.append(n_err / len(r_x))\n","\n","    # Calculate aggregate error rate\n","    error_rate_agg = np.sum(err_count) / np.sum(item_count)\n","\n","    # calculate 95% CI\n","    item_count = np.array(item_count)\n","    err_count = np.array(err_count)\n","    nResamples = 10000\n","    resampled_error_rate = np.zeros([nResamples,])\n","    for n in range(nResamples):\n","        resampleIdx = np.random.randint(0, item_count.shape[0], [item_count.shape[0]])\n","        resampled_error_rate[n] = np.sum(err_count[resampleIdx]) / np.sum(item_count[resampleIdx])\n","    error_rate_agg_CI = np.percentile(resampled_error_rate, [2.5, 97.5])\n","\n","    # return everything as a tuple\n","    return (error_rate_agg, error_rate_agg_CI[0], error_rate_agg_CI[1], error_rate_ind)"]}]}